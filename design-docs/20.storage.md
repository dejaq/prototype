# Storage 
Most of the properties of the system will be put in the storage responsibility:
Persistence
Scalability
Durability
High-concurrency (with document level atomic operations)
Fault-tolerance (replicas)
Low-latency


I will try to implement a few storage systems as the backend, it has to support:
Range queries on timeline  O(logn) complexity, preferable O(1)
Lookup by ID O(logn) complexity, preferable O(1)
ACID 
Conditional mutations (preferable scripting)
 * []byte/blob type support

Good to have:
Secondary indexes (for some features)
Sharding 
Fast count aggregations
Strong consistency 

Storage consideration: try to separate the documents between mutable and immutable data, or by usage. 
ID, BucketID and Timestamp are extensively used for queries. Timestamp is Mutable, and body can be very large.


## In memory (broker)
This implementation will serve 2 purposes: highest performance and for testing. In the first iteration replicas will not be developed. It will never have persistence (most likely).
TODO research: probably we will use Golang miniredis so we can reuse the code from the Redis implementation.
## External cluster 
Although we will have our own embedded storage (like kafka) the first iterations will use external databases. 
### Redis (???? owner)
Redis will be our prime and default external storage for non-production environments.

### SQL (owner David)
We will have an official SQL like support with the Go-standard library. It will work with MariaDB, PostgreSQL, MySQL and others probably. 
Schema: 
primaryID; messageID
Timeline: secondaryIndex on Timestamp
Secondary index: LockConsumerID
Secondary index: ProducerOwnerID
Body storage schema: see storage - body
### CockroachDB (owner Adrian)
TODO: research on schema 

### Cassandra (owner Mihai)
TODO: research on 3 schemas:
Time slice based (when the USER specify the interval, like Riak TS)
Time slice with max number of messages (when an interval is full create a new partition key for the same time slice. Writes will be done in the latest, reads from all)
Distributed - partition key is the ID, no time slice

### Why not metric based DBs (Open TSBD, RiakTS, Prometheus/Cortex)
Metric-based databases are not compatible with timeline.  is hard to use these DBs because we can have multiple messages at the same timestamp. Also we need to query by messageID. 

## Consistency
The consistency will be set by the Client for each client, when the Handshake is done. It affects all the writes done on that channel. 

Enum WriteConsistency  ?!?!?!!? TODO decide this 
None (fire&forget)
master
Quorum 
All


|             	| In memory 	| Redis 	| Redis cluster/sentinel                              	| SQL 	| Cassandra                                              	| CockroachDB 	|
|-------------	|-----------	|-------	|-----------------------------------------------------	|-----	|--------------------------------------------------------	|-------------	|
| none        	| yes       	| yes   	| yes                                                 	| yes 	| yes                                                    	| yes         	|
| master      	| yes       	| yes   	| yes                                                 	| yes 	| yes                                                    	| yes         	|
| quorum      	| N/A       	| N/A   	| ???                                                 	| ??? 	| ???                                                    	| ???         	|
| all         	| N/A       	| N/A   	| ???                                                 	| ??? 	| ???                                                    	| ???         	|
| ????        	|           	|       	|                                                     	|     	|                                                        	|             	|
| Subscribe   	|           	| CTB   	| Must be an unsubscribed consumer.                   	| R   	| Error error                                            	|             	|
| Unsubscribe 	|           	| CTB   	| Must be subscribed                                  	|     	| Error error                                            	|             	|
| Info        	|           	| CTB   	| Fetch the latest metadata consensus from the broke. 	| R   	| Metadata metadata (see SyncrnizationService consensus) 	|             	|














## Provisioning
Creating and deleting topics will be allowed through the protocol.
The SDK, CLI and any other client will be able to make the calls. 
Some storage systems are more complex than others and the call may fail (eg: create a new table).
Also the Systems Administrators may restrict the System to create new resources (eg: the SQL users cannot create new tables). 

The User will define a “naming” pattern that will affect the Tables/Topics names in the external clusters in the Brokers config. Eg: 
Timeline pattern: “queue_timeline_*” in SQL, with a timeline called “christmasSale” will generate the tables: “queue_timeline_christmasSale_timeline” and “queue_timeline_christmasSale_body”.

## Body storage
Each topic type will have a distinct need of storage and data structures. The main and common need of all topics will be the body. To avoid performance penalties on topics the body of the messages are stored separately.

Each topic will have its own body table. An example of the schema is:
BodyID: messageID (string)
Body: []bytes

